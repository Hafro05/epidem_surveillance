#!/usr/bin/env python3
"""
Script d'ingestion pour la surveillance √©pid√©miologique
Source: Our World in Data COVID-19 dataset
"""

import pandas as pd
import requests
from pathlib import Path
from datetime import datetime
import logging
import os

# Configuration
RAW_DATA_URL = "https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
DATA_DIR = Path("data")
RAW_DIR = DATA_DIR / "raw" 
PROCESSED_DIR = DATA_DIR / "processed"

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ingestion.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def setup_directories():
    """Cr√©e la structure des dossiers si elle n'existe pas"""
    for directory in [RAW_DIR, PROCESSED_DIR]:
        directory.mkdir(parents=True, exist_ok=True)
    logger.info("Structure des dossiers cr√©√©e")

def download_data():
    """T√©l√©charge les donn√©es depuis Our World in Data"""
    try:
        logger.info(f"D√©but du t√©l√©chargement depuis {RAW_DATA_URL}")
        
        # T√©l√©chargement avec timeout
        response = requests.get(RAW_DATA_URL, timeout=30)
        response.raise_for_status()
        
        # G√©n√©ration du nom de fichier avec timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"owid_covid_data_{timestamp}.csv"
        filepath = RAW_DIR / filename
        
        # Sauvegarde
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        logger.info(f"Donn√©es t√©l√©charg√©es avec succ√®s : {filepath}")
        logger.info(f"Taille du fichier : {filepath.stat().st_size / (1024*1024):.2f} MB")
        
        return filepath
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Erreur lors du t√©l√©chargement : {e}")
        raise
    except Exception as e:
        logger.error(f"Erreur inattendue : {e}")
        raise

def validate_data(filepath):
    """Valide basiquement les donn√©es t√©l√©charg√©es"""
    try:
        logger.info("D√©but de la validation des donn√©es")
        
        # Lecture du fichier
        df = pd.read_csv(filepath)
        
        # V√©rifications de base
        logger.info(f"Nombre de lignes : {len(df):,}")
        logger.info(f"Nombre de colonnes : {len(df.columns)}")
        logger.info(f"P√©riode couverte : {df['date'].min()} √† {df['date'].max()}")
        logger.info(f"Nombre de pays : {df['location'].nunique()}")
        
        # V√©rifications critiques
        required_columns = ['date', 'location', 'total_cases', 'new_cases']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"Colonnes manquantes : {missing_columns}")
        
        # V√©rification que nous avons des donn√©es r√©centes (derni√®res 7 jours)
        df['date'] = pd.to_datetime(df['date'])
        latest_date = df['date'].max()
        days_old = (datetime.now().date() - latest_date.date()).days
        
        if days_old > 7:
            logger.warning(f"Donn√©es anciennes : {days_old} jours")
        else:
            logger.info(f"Donn√©es r√©centes : {days_old} jours d'anciennet√©")
        
        logger.info("‚úÖ Validation des donn√©es r√©ussie")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la validation : {e}")
        raise

def create_latest_symlink(filepath):
    """Cr√©e un lien symbolique vers le fichier le plus r√©cent"""
    try:
        latest_link = RAW_DIR / "latest_owid_covid_data.csv"
        
        # Supprime l'ancien lien s'il existe
        if latest_link.exists():
            latest_link.unlink()
        
        # Cr√©e le nouveau lien
        latest_link.symlink_to(filepath.name)
        logger.info(f"Lien symbolique cr√©√© : {latest_link}")
        
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation du lien symbolique : {e}")
        # Non critique, on continue

def main():
    """Fonction principale d'ingestion"""
    try:
        logger.info("üöÄ D√©but du processus d'ingestion")
        
        # 1. Configuration des dossiers
        setup_directories()
        
        # 2. T√©l√©chargement
        filepath = download_data()
        
        # 3. Validation
        validate_data(filepath)
        
        # 4. Cr√©ation du lien symbolique
        create_latest_symlink(filepath)
        
        logger.info("‚úÖ Processus d'ingestion termin√© avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå √âchec du processus d'ingestion : {e}")
        raise

if __name__ == "__main__":
    main()#!/usr/bin/env python3
"""
Script d'ingestion pour la surveillance √©pid√©miologique
Source: Our World in Data COVID-19 dataset
"""

import pandas as pd
import requests
from pathlib import Path
from datetime import datetime
import logging
import os

# Configuration
RAW_DATA_URL = "https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
DATA_DIR = Path("data")
RAW_DIR = DATA_DIR / "raw" 
PROCESSED_DIR = DATA_DIR / "processed"

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ingestion.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def setup_directories():
    """Cr√©e la structure des dossiers si elle n'existe pas"""
    for directory in [RAW_DIR, PROCESSED_DIR]:
        directory.mkdir(parents=True, exist_ok=True)
    logger.info("Structure des dossiers cr√©√©e")

def download_data():
    """T√©l√©charge les donn√©es depuis Our World in Data"""
    try:
        logger.info(f"D√©but du t√©l√©chargement depuis {RAW_DATA_URL}")
        
        # T√©l√©chargement avec timeout
        response = requests.get(RAW_DATA_URL, timeout=30)
        response.raise_for_status()
        
        # G√©n√©ration du nom de fichier avec timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"owid_covid_data_{timestamp}.csv"
        filepath = RAW_DIR / filename
        
        # Sauvegarde
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        logger.info(f"Donn√©es t√©l√©charg√©es avec succ√®s : {filepath}")
        logger.info(f"Taille du fichier : {filepath.stat().st_size / (1024*1024):.2f} MB")
        
        return filepath
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Erreur lors du t√©l√©chargement : {e}")
        raise
    except Exception as e:
        logger.error(f"Erreur inattendue : {e}")
        raise

def validate_data(filepath):
    """Valide basiquement les donn√©es t√©l√©charg√©es"""
    try:
        logger.info("D√©but de la validation des donn√©es")
        
        # Lecture du fichier
        df = pd.read_csv(filepath)
        
        # V√©rifications de base
        logger.info(f"Nombre de lignes : {len(df):,}")
        logger.info(f"Nombre de colonnes : {len(df.columns)}")
        logger.info(f"P√©riode couverte : {df['date'].min()} √† {df['date'].max()}")
        logger.info(f"Nombre de pays : {df['location'].nunique()}")
        
        # V√©rifications critiques
        required_columns = ['date', 'location', 'total_cases', 'new_cases']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"Colonnes manquantes : {missing_columns}")
        
        # V√©rification que nous avons des donn√©es r√©centes (derni√®res 7 jours)
        df['date'] = pd.to_datetime(df['date'])
        latest_date = df['date'].max()
        days_old = (datetime.now().date() - latest_date.date()).days
        
        if days_old > 7:
            logger.warning(f"Donn√©es anciennes : {days_old} jours")
        else:
            logger.info(f"Donn√©es r√©centes : {days_old} jours d'anciennet√©")
        
        logger.info("‚úÖ Validation des donn√©es r√©ussie")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la validation : {e}")
        raise

def create_latest_symlink(filepath):
    """Cr√©e un lien symbolique vers le fichier le plus r√©cent"""
    try:
        latest_link = RAW_DIR / "latest_owid_covid_data.csv"
        
        # Supprime l'ancien lien s'il existe
        if latest_link.exists():
            latest_link.unlink()
        
        # Cr√©e le nouveau lien
        latest_link.symlink_to(filepath.name)
        logger.info(f"Lien symbolique cr√©√© : {latest_link}")
        
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation du lien symbolique : {e}")
        # Non critique, on continue

def main():
    """Fonction principale d'ingestion"""
    try:
        logger.info("üöÄ D√©but du processus d'ingestion")
        
        # 1. Configuration des dossiers
        setup_directories()
        
        # 2. T√©l√©chargement
        filepath = download_data()
        
        # 3. Validation
        validate_data(filepath)
        
        # 4. Cr√©ation du lien symbolique
        create_latest_symlink(filepath)
        
        logger.info("‚úÖ Processus d'ingestion termin√© avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå √âchec du processus d'ingestion : {e}")
        raise

if __name__ == "__main__":
    main()